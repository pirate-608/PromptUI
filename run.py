import os
import sys
import subprocess
import shutil
import threading
import time
import webbrowser

from dotenv import load_dotenv


# --- æå‰å®šä¹‰ pull_ollama_model ---
def pull_ollama_model():
    """
    è‡ªåŠ¨æ‹‰å– Ollama æ¨¡å‹ï¼Œæ¨¡å‹åä» OLLAMA_MODEL ç¯å¢ƒå˜é‡è¯»å–ï¼ˆæ— åˆ™é»˜è®¤ llama3ï¼‰
    """
    model = os.getenv("OLLAMA_MODEL") or os.getenv("LLM_MODEL") or "llama3"
    if not shutil.which("ollama"):
        print("[Ollama] è·³è¿‡æ¨¡å‹æ‹‰å–ï¼Œæœªæ£€æµ‹åˆ° ollama å¯æ‰§è¡Œæ–‡ä»¶ã€‚")
        return
    print(f"[Ollama] æ£€æŸ¥æ¨¡å‹ï¼š{model}")
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
    try:
        result = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True, check=True
        )
        if model in result.stdout:
            print(f"[Ollama] å·²å­˜åœ¨æ¨¡å‹ï¼š{model}")
            return
    except Exception as e:
        print(f"[Ollama] æ£€æŸ¥æ¨¡å‹å¤±è´¥ï¼š{e}")
        # ç»§ç»­å°è¯•æ‹‰å–
    print(f"[Ollama] æ‹‰å–æ¨¡å‹ï¼š{model} ...")
    try:
        subprocess.run(["ollama", "pull", model], check=True)
        print(f"[Ollama] âœ… æ¨¡å‹æ‹‰å–å®Œæˆï¼š{model}")
    except Exception as e:
        print(f"[Ollama] âŒ æ¨¡å‹æ‹‰å–å¤±è´¥ï¼š{e}")


# --- æ‰“åŒ…ç¯å¢ƒä¸‹è‡ªåŠ¨åˆ‡æ¢å·¥ä½œç›®å½•åˆ° _internal ---
if getattr(sys, "frozen", False):
    # sys._MEIPASS æ˜¯ PyInstaller çš„ä¸´æ—¶è§£åŒ…ç›®å½•
    base_dir = getattr(sys, "_MEIPASS", None)
    if base_dir:
        internal_dir = os.path.join(base_dir, "_internal")
        if os.path.isdir(internal_dir):
            os.chdir(internal_dir)
            print(f"[PromptUI] åˆ‡æ¢å·¥ä½œç›®å½•åˆ°: {internal_dir}")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def check_and_install_ollama():
    """
    æ£€æµ‹ Ollama æ˜¯å¦å®‰è£…ï¼Œæœªå®‰è£…åˆ™å°è¯•è‡ªåŠ¨å®‰è£… (ä»…é™ Windows)
    """
    print("ğŸ” Checking system dependencies...")

    # ä¼˜å…ˆè¯»å– .env ä¸­ OLLAMA_PATH å¹¶åŠ å…¥ PATH
    ollama_path = os.getenv("OLLAMA_PATH")
    if ollama_path:
        # å…¼å®¹å¤šè·¯å¾„ï¼ˆåˆ†å·åˆ†éš”ï¼‰
        paths = ollama_path.split(";")
        for p in paths:
            p = p.strip()
            if p and p not in os.environ.get("PATH", ""):
                os.environ["PATH"] = p + ";" + os.environ["PATH"]
        print(f"ğŸ”§ OLLAMA_PATH added to PATH: {ollama_path}")

    if shutil.which("ollama"):
        print("âœ… Ollama detected.")
        return

    print("âš ï¸ Ollama not found in PATH.")
    print("Ollama is recommended for local AI inference.")

    # ä»…åœ¨éé™é»˜æ¨¡å¼ä¸‹è¯¢é—®ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´äº¤äº’é€»è¾‘ï¼‰
    choice = (
        input("ğŸ‘‰ Do you want to download and install Ollama automatically? (y/n): ")
        .strip()
        .lower()
    )

    if choice == "y":
        platform = sys.platform
        if platform.startswith("win"):
            print("ğŸš€ Downloading and installing Ollama (via PowerShell)...")
            print("   (Please allow Administrator privileges if requested)")
            ps_command = "irm https://ollama.com/install.ps1 | iex"
            try:
                subprocess.run(["powershell", "-Command", ps_command], check=True)
                print(
                    "âœ… Ollama installed successfully! You may need to restart the app."
                )
            except subprocess.CalledProcessError as e:
                print(f"âŒ Installation failed: {e}")
                print("Please install manually from: https://ollama.com")
            except Exception as e:
                print(f"âŒ Unexpected error: {e}")
        elif (
            platform == "darwin"
            or platform.startswith("linux")
            or platform.startswith("cygwin")
        ):
            print("ğŸš€ Downloading and installing Ollama (via curl)...")
            curl_cmd = "curl -fsSL https://ollama.com/install.sh | sh"
            try:
                subprocess.run(curl_cmd, shell=True, check=True, executable="/bin/bash")
                print(
                    "âœ… Ollama installed successfully! You may need to restart the app."
                )
            except subprocess.CalledProcessError as e:
                print(f"âŒ Installation failed: {e}")
                print("Please install manually from: https://ollama.com")
            except Exception as e:
                print(f"âŒ Unexpected error: {e}")
        else:
            print(
                f"âŒ Unsupported platform: {platform}. Please install Ollama manually from https://ollama.com"
            )
    else:
        print("â© Skipping Ollama installation.")


def open_browser(url):
    """å»¶è¿Ÿæ‰“å¼€æµè§ˆå™¨"""
    time.sleep(2)
    webbrowser.open(url)


def run_app():
    # 1. å¯åŠ¨å‰æ£€æŸ¥
    check_and_install_ollama()
    pull_ollama_model()

    host = os.getenv("HOST", "127.0.0.1")
    port = int(os.getenv("PORT", "8000"))
    url = f"http://{host}:{port}"

    # 2. åŒºåˆ†è¿è¡Œæ¨¡å¼
    if getattr(sys, "frozen", False):
        # --- æ‰“åŒ…åçš„ EXE æ¨¡å¼ ---
        import uvicorn

        # æ˜¾å¼å¯¼å…¥ app.mainï¼Œé˜²æ­¢ PyInstaller æ‰¾ä¸åˆ°æ¨¡å—
        import app.main

        print(f"ğŸš€ Starting PromptUI (Production Mode) at {url}")

        # å¯åŠ¨æµè§ˆå™¨çº¿ç¨‹
        threading.Thread(target=open_browser, args=(url,), daemon=True).start()

        # ç›´æ¥ä¼ é€’ app å¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²ï¼Œé¿å…æ‰“åŒ…åçš„å¯¼å…¥è·¯å¾„é—®é¢˜
        # log_level="error" ä¿æŒç•Œé¢æ¸…çˆ½
        uvicorn.run(app.main.app, host=host, port=port, log_level="info")

    else:
        # --- å¼€å‘æ¨¡å¼ ---
        print(f"ğŸ› ï¸ Starting PromptUI (Dev Mode) at {url}")

        # å¼€å‘æ¨¡å¼ä½¿ç”¨å­—ç¬¦ä¸²å¯¼å…¥ï¼Œä»¥æ”¯æŒ --reload çƒ­é‡è½½
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ä½ å·²ç»åœ¨ promptui/ æ ¹ç›®å½•ä¸‹è¿è¡Œ
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆå¯é€‰ï¼Œå¼€å‘æ—¶å¯èƒ½ä¸æƒ³æ¯æ¬¡éƒ½å¼¹çª—ï¼Œè¿™é‡ŒåŠ ä¸Šé˜²æ­¢ä¸ºäº†ä¿æŒä¸€è‡´ï¼‰
        threading.Thread(target=open_browser, args=(url,), daemon=True).start()

        # ä½¿ç”¨ os.system æˆ– subprocess è°ƒç”¨ uvicorn CLI ä»¥æ”¯æŒ reload
        # å¿…é¡»ç¡®ä¿å½“å‰ç›®å½•æ˜¯ promptui/
        os.system(f"uvicorn app.main:app --host {host} --port {port} --reload")


if __name__ == "__main__":
    try:
        run_app()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Goodbye!")
        sys.exit(0)
